{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Batch Job Analysis - Data Prepare - Extract from SMF \n",
    "*Note: for reference only, no input/output sample data file provided*\n",
    "\n",
    "**This sample notebook will demonstrate how to extract Batch Job log data from SMF Type 30 record and prepare for further analytics.**\n",
    "\n",
    "Input data file is n days of SMF Type 30 record collected on z/OS named as HLQ.T2019XXXX.SMF30:<br>\n",
    ">   HLQ.T20190001.SMF30<br> \n",
    "   HLQ.T20190002.SMF30<br>\n",
    "   HLQ.T20190003.SMF30<br>\n",
    "   .................<br>\n",
    "   \n",
    "\n",
    "**Key Steps includes:**\n",
    "1. Extract everyday's batch jobs log data from SMF Type 30 record\n",
    "2. Combine n days jobs data from csv files into one data frame for analysis\n",
    "3. Remove uninterested batch job records\n",
    "4. Calculate some interested metrics from original data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## Step 1: Extract batch job run log data from SMF Type 30 record\n",
    "\n",
    "**Demonstrate how to read SMF Type 30 record into dataframe  **</p>\n",
    "***Note:***\n",
    ">1.It should be run on WMLz Platform with MDS(Mainframe Data Service) driver installed<br>\n",
    "2.Ask for your MDS administrator for ssid,username and password<br>\n",
    "3.With Mainframe Data Service Studio, you could get predefined SQL statement and view for SMF Type 30 record<br>\n",
    "4.Refer to SMF Type 30 document to understand every metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import dsdbc\n",
    "CONN = dsdbc.connect(SSID='MDS_ssid', USER='MDS_user', PASSWORD='MDS_password')\n",
    "\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "#path variable for SMF data output path, when change to another environment, need to change it according to data file location \n",
    "SMF_DATA_PATH=r\"/username/smf/\"\n",
    "\n",
    "\n",
    "START_TIME=datetime.datetime.now()\n",
    "print(\"Start:\",START_TIME)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FIRST_DAY=1\n",
    "LAST_DAY=91\n",
    "\n",
    "\n",
    "\n",
    "for INDEX in range(FIRST_DAY,LAST_DAY,1):\n",
    "   #to read SMF Type 30 record from mainframe system, HLQ.T2019001.SMF30 to get day 001 information, \n",
    "   #write to a csv file as 'df_D0001.csv' for further merge\n",
    "   #SMF record size maybe very large, recommand to start from small file, e.g. seperate by day\n",
    "   #convert to csv file will make further processing fast and convinient \n",
    "\n",
    "    DAY_STR=str(INDEX).rjust(4,'0')\n",
    "    \n",
    "    SMF_FILE_PRE='SMF_03000'\n",
    "    SMF_FILE_POST= \"__HLQ_T2019\"+DAY_STR+\"_SMF30\" #align to real SMF record name\n",
    "    SMF_30_TABLE = SMF_FILE_PRE+SMF_FILE_POST\n",
    "    SMF_FILE_PRE='SMF_03000_SMF30'\n",
    "    SMF_30_ID_TABLE = SMF_FILE_PRE+'ID'+SMF_FILE_POST\n",
    "    SMF_30_CAS_TABLE = SMF_FILE_PRE+'CAS'+SMF_FILE_POST\n",
    "    SMF_30_PRF_TABLE = SMF_FILE_PRE+'PRF'+SMF_FILE_POST\n",
    "    SMF_30_URA_TABLE = SMF_FILE_PRE+'URA'+SMF_FILE_POST\n",
    "    SMF_30_SAP_TABLE = SMF_FILE_PRE+'SAP'+SMF_FILE_POST\n",
    "    \n",
    "    \n",
    "    QUERY='select SMF30JBN As JOB_NAME,SMF30JNM AS JOB_NUM,SMF_SSI AS TYPE,SMF_SID as SYSTEM,SMF30CLS as CLASS,\\\n",
    "    SMF30RSD as REQUEST_D,SMF30RST REQUEST_T,SMF30STD START_D,SMF30SIT as START_T,\\\n",
    "    SUBSTR(SMF_TIME,1,10) AS END_D,SUBSTR(SMF_TIME,12,11) AS END_T,\\\n",
    "    SUBSTR(SMF_TIME,1,23) AS END_DTSTR,\\\n",
    "    CAS.SMF30CPT/100 as TCB_CPU_SEC,CAS.SMF30CPS/100 as SRB_CPU_SEC,\\\n",
    "    (SMF30CSU /160000)  * SMF30SUS  as TCB_CPU_MS,\\\n",
    "    (SMF30SRB /160000)  * SMF30SUS  as SRB_CPU_MS,\\\n",
    "    URA.SMF30TEP as EXCP,(URA.SMF30TCN/1000000)*128 as IO_CONN_SEC,URA.SMF30AIS as SSCH,\\\n",
    "    PRF.SMF30SRV as SERV_UNIT,PRF.SMF30CSU as TCB_UNIT,PRF.SMF30SRB as SRB_UNIT,PRF.SMF30IO as IO_UNIT,PRF.SMF30MSO as MSO_UNIT,\\\n",
    "    (PRF.SMF30JQT*1024/1000000) as JQ_SEC,(PRF.SMF30RQT*1024/1000000) as RQ_SEC,\\\n",
    "    (PRF.SMF30HQT*1024/1000000) as HQ_SEC,(PRF.SMF30SQT*1024/1000000) as SQ_SEC,\\\n",
    "    PRF.SMF30SCN as SERV_CLASS,\\\n",
    "    ID.SMF30USR as USER_NAME,\\\n",
    "    SAP.SMF30PGI as PAGE_IN,SAP.SMF30PGO as PAGE_OUT,SAP.SMF30NSW as PAGE_SWAP \\\n",
    "    FROM '+SMF_30_TABLE+' A0 \\\n",
    "    JOIN '+SMF_30_ID_TABLE+' ID ON A0.CHILD_KEY=ID.PARENT_KEY \\\n",
    "    JOIN '+SMF_30_PRF_TABLE+' PRF ON A0.CHILD_KEY=PRF.PARENT_KEY \\\n",
    "    JOIN '+SMF_30_CAS_TABLE+' CAS ON A0.CHILD_KEY=CAS.PARENT_KEY \\\n",
    "    JOIN '+SMF_30_URA_TABLE+' URA ON A0.CHILD_KEY=URA.PARENT_KEY \\\n",
    "    JOIN '+SMF_30_SAP_TABLE+' SAP ON A0.CHILD_KEY=SAP.PARENT_KEY \\\n",
    "    where A0.SMF_STY=5'\n",
    "    \n",
    "    #following statement will extract data from SMF record, may cost some time according to you SMF record size\n",
    "    DF=pd.read_sql(QUERY,con=CONN)\n",
    "    DF.to_csv(SMF_DATA_PATH +\"df_D\"+ DAY_STR + \".csv\")\n",
    "    print(\"After write \"+\"df_D\"+ DAY_STR + \".csv\",datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## Step 2: Merge n days jobs data from n csv files into one file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculation for SMF record for everyday's data, and then merge\n",
    "DF = pd.DataFrame()\n",
    "\n",
    "for INDEX in range(FIRST_DAY,LAST_DAY,1):\n",
    "    SMF_30_FILE = SMF_DATA_PATH +\"df_D\"+ str(INDEX).rjust(4,'0') + \".csv\"\n",
    "    DF_1D=pd.read_csv(SMF_30_FILE, encoding='ISO-8859-1')\n",
    "    DF=DF.append(DF_1D)\n",
    "DF.to_csv(SMF_DATA_PATH+'df_all.csv')   \n",
    "\n",
    "print(\"After write df_all.csv:\",datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "## Step 3: Remove uninterested batch job records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#read from the merged CSV file, \n",
    "#it could be a start point when you collect all necessary data from SMF\n",
    "\n",
    "DF=pd.read_csv(SMF_DATA_PATH+'df_all.csv',encoding='ISO-8859-1')\n",
    "print(\"After read df_all.csv:\",datetime.datetime.now())\n",
    "\n",
    "#only focused on batch window between 20pm to 1d+6am\n",
    "DF['is_focused']=DF['START_T'].apply(lambda t:(t>=7200000) or (t<2160000))\n",
    "DF=DF[DF['is_focused']==True].drop('is_focused',axis=1)\n",
    "#only focused on jobs with 'JOBxxxxxx' JESID\n",
    "DF['is_focused']=DF['JOB_NUM'].apply(lambda num:num[0:3]=='JOB')\n",
    "DF=DF[DF['is_focused']==True].drop('is_focused',axis=1)\n",
    "#remove BATCHXXX which may run several days\n",
    "DF['is_focused']=DF['SERV_CLASS'].apply(lambda s:s!='BATCHXXX')\n",
    "DF=DF[DF['is_focused']==True].drop('is_focused',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "\n",
    "## Step 4: Calculate some interested metrics from original SMF record \n",
    "   - START_DT: job start running date and time\n",
    "   - END_DT: job finish date and time\n",
    "   - ELAPSED_TIME: duration of job run, the second between START_DT and END_DT\n",
    "   - CPU_SEC: second of CPU run time on the job\n",
    "   - QUEUE_SEC: second of job waiting in various queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#translate SMF datetime to normal python datetine\n",
    "import datetime, time\n",
    "\n",
    "def SmfConv2Dt(d,t):\n",
    "    YYY=int(int(d)/1000)\n",
    "    DDD=int(d)-1000*YYY\n",
    "    DT=datetime.datetime(YYY+1900,1,1)+datetime.timedelta(days=DDD-1)+datetime.timedelta(seconds=t/100)\n",
    "    return DT\n",
    "\n",
    "\n",
    "def Dt2Sec(DT):\n",
    "    SEC=(DT-datetime.datetime(1970,1,1))/datetime.timedelta(seconds=1)\n",
    "    return SEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DF['START_DT']=DF.apply(lambda row:SmfConv2Dt(row['START_D'],row['START_T']),axis=1)\n",
    "DF['START_DTSTR']=DF['START_DT'].apply(lambda dt:datetime.datetime.strftime(dt,'%Y-%m-%d-%H.%M.%S.000000'))\n",
    "DF['START_SEC']=DF['START_DT'].apply(lambda dt:Dt2Sec(dt))\n",
    "\n",
    "DF['REQUEST_DT']=DF.apply(lambda row:SmfConv2Dt(row['REQUEST_D'],row['REQUEST_T']),axis=1)\n",
    "DF['REQUEST_SEC']=DF['REQUEST_DT'].apply(lambda dt:Dt2Sec(dt))\n",
    "\n",
    "DF['END_DT']=DF['END_DTSTR'].apply(lambda dt_str:datetime.datetime.strptime(dt_str,'%Y-%m-%d-%H.%M.%S.%f'))\n",
    "DF['END_SEC']=DF['END_DT'].apply(lambda dt:Dt2Sec(dt))\n",
    "\n",
    "DF['ELAPSED_SEC']=DF['END_SEC']-DF['START_SEC']\n",
    "\n",
    "\n",
    "DF['CPU_SEC']=DF['TCB_CPU_SEC']+DF['SRB_CPU_SEC']\n",
    "DF['CPU_MS']=DF['TCB_CPU_MS']+DF['SRB_CPU_MS']\n",
    "\n",
    "DF['QUEUE_SEC']=DF['JQ_SEC']+DF['RQ_SEC']+DF['HQ_SEC']+DF['SQ_SEC']\n",
    "\n",
    "#set job's batch_date as D-1 when START_TIME is earlier than 6am\n",
    "DF['BATCH_DATE']=DF['START_DT'].apply(lambda dt:datetime.datetime.date(dt+datetime.timedelta(hours=-6)))\n",
    "\n",
    "print(DF.shape)\n",
    "print(DF.head(5))\n",
    "DF.to_csv(SMF_DATA_PATH+'df_smf.csv',index=False)\n",
    "print(\"After write df_smf.csv:\",datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print end time used for data processing\n",
    "#to prepare data in large size may cost long time\n",
    "END_TIME=datetime.datetime.now()\n",
    "print(\"Finish:\",END_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample output of smf data extracted from previous steps\n",
    "In sample dataset, df_smf is sample data extracted from previous steps <p>\n",
    "Following fields are useful for further elapsed time analysis: <p>\n",
    ">JOB_NAME: Job name defined by user <br>\n",
    "JOB_NUM:  Job instance number <br>\n",
    "START_D:  Job start date<br>\n",
    "START_T:  Job start time<br>\n",
    "START_DTSTR: Job start date time in string format<br>\n",
    "END_D:    Job end date<br>\n",
    "END_T:    Job end time<br>\n",
    "END_DTSTR:   Job end date time in string format<br>\n",
    "ELAPSED_SEC: Job elapsed time in second <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>END_D</th>\n",
       "      <th>END_DTSTR</th>\n",
       "      <th>END_T</th>\n",
       "      <th>EXCP</th>\n",
       "      <th>HQ_SEC</th>\n",
       "      <th>IO_CONN_SEC</th>\n",
       "      <th>IO_UNIT</th>\n",
       "      <th>JOB_NAME</th>\n",
       "      <th>JOB_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>START_SEC</th>\n",
       "      <th>REQUEST_DT</th>\n",
       "      <th>REQUEST_SEC</th>\n",
       "      <th>END_DT</th>\n",
       "      <th>END_SEC</th>\n",
       "      <th>ELAPSED_SEC</th>\n",
       "      <th>CPU_SEC</th>\n",
       "      <th>CPU_MS</th>\n",
       "      <th>QUEUE_SEC</th>\n",
       "      <th>BATCH_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2018/8/1</td>\n",
       "      <td>2018-08-01-00.01.44.850</td>\n",
       "      <td>00.01.44.85</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>JN_001</td>\n",
       "      <td>JOB35880</td>\n",
       "      <td>...</td>\n",
       "      <td>1533081526</td>\n",
       "      <td>58:45.3</td>\n",
       "      <td>1533081525</td>\n",
       "      <td>01:44.8</td>\n",
       "      <td>1533081705</td>\n",
       "      <td>178.75</td>\n",
       "      <td>10</td>\n",
       "      <td>10907</td>\n",
       "      <td>2</td>\n",
       "      <td>2018/7/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>2018/8/1</td>\n",
       "      <td>2018-08-01-00.01.32.720</td>\n",
       "      <td>00.01.32.72</td>\n",
       "      <td>65147</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>293934</td>\n",
       "      <td>JN_002</td>\n",
       "      <td>JOB36624</td>\n",
       "      <td>...</td>\n",
       "      <td>1533081639</td>\n",
       "      <td>00:30.6</td>\n",
       "      <td>1533081631</td>\n",
       "      <td>01:32.7</td>\n",
       "      <td>1533081693</td>\n",
       "      <td>53.28</td>\n",
       "      <td>10</td>\n",
       "      <td>10747</td>\n",
       "      <td>9</td>\n",
       "      <td>2018/7/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2018/8/1</td>\n",
       "      <td>2018-08-01-00.02.56.380</td>\n",
       "      <td>00.02.56.38</td>\n",
       "      <td>47312</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>190858</td>\n",
       "      <td>JN_002</td>\n",
       "      <td>JOB37496</td>\n",
       "      <td>...</td>\n",
       "      <td>1533081695</td>\n",
       "      <td>01:33.2</td>\n",
       "      <td>1533081693</td>\n",
       "      <td>02:56.4</td>\n",
       "      <td>1533081776</td>\n",
       "      <td>81.11</td>\n",
       "      <td>33</td>\n",
       "      <td>35357</td>\n",
       "      <td>2</td>\n",
       "      <td>2018/7/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2018/8/1</td>\n",
       "      <td>2018-08-01-00.04.57.270</td>\n",
       "      <td>00.04.57.27</td>\n",
       "      <td>266848</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>1015707</td>\n",
       "      <td>JN_003</td>\n",
       "      <td>JOB35916</td>\n",
       "      <td>...</td>\n",
       "      <td>1533081576</td>\n",
       "      <td>58:51.7</td>\n",
       "      <td>1533081532</td>\n",
       "      <td>04:57.3</td>\n",
       "      <td>1533081897</td>\n",
       "      <td>321.32</td>\n",
       "      <td>206</td>\n",
       "      <td>218757</td>\n",
       "      <td>44</td>\n",
       "      <td>2018/7/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>2018/8/1</td>\n",
       "      <td>2018-08-01-00.02.02.810</td>\n",
       "      <td>00.02.02.81</td>\n",
       "      <td>142618</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>609758</td>\n",
       "      <td>JN_004</td>\n",
       "      <td>JOB35536</td>\n",
       "      <td>...</td>\n",
       "      <td>1533081503</td>\n",
       "      <td>57:57.2</td>\n",
       "      <td>1533081477</td>\n",
       "      <td>02:02.8</td>\n",
       "      <td>1533081723</td>\n",
       "      <td>220.12</td>\n",
       "      <td>88</td>\n",
       "      <td>94262</td>\n",
       "      <td>25</td>\n",
       "      <td>2018/7/31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS     END_D                END_DTSTR        END_T    EXCP  HQ_SEC  \\\n",
       "0    100  2018/8/1  2018-08-01-00.01.44.850  00.01.44.85     148       0   \n",
       "1    100  2018/8/1  2018-08-01-00.01.32.720  00.01.32.72   65147       0   \n",
       "2    100  2018/8/1  2018-08-01-00.02.56.380  00.02.56.38   47312       0   \n",
       "3    100  2018/8/1  2018-08-01-00.04.57.270  00.04.57.27  266848       0   \n",
       "4    100  2018/8/1  2018-08-01-00.02.02.810  00.02.02.81  142618       0   \n",
       "\n",
       "   IO_CONN_SEC  IO_UNIT JOB_NAME   JOB_NUM     ...       START_SEC  \\\n",
       "0            0      695   JN_001  JOB35880     ...      1533081526   \n",
       "1           27   293934   JN_002  JOB36624     ...      1533081639   \n",
       "2           48   190858   JN_002  JOB37496     ...      1533081695   \n",
       "3          335  1015707   JN_003  JOB35916     ...      1533081576   \n",
       "4          148   609758   JN_004  JOB35536     ...      1533081503   \n",
       "\n",
       "   REQUEST_DT  REQUEST_SEC   END_DT     END_SEC  ELAPSED_SEC  CPU_SEC  CPU_MS  \\\n",
       "0     58:45.3   1533081525  01:44.8  1533081705       178.75       10   10907   \n",
       "1     00:30.6   1533081631  01:32.7  1533081693        53.28       10   10747   \n",
       "2     01:33.2   1533081693  02:56.4  1533081776        81.11       33   35357   \n",
       "3     58:51.7   1533081532  04:57.3  1533081897       321.32      206  218757   \n",
       "4     57:57.2   1533081477  02:02.8  1533081723       220.12       88   94262   \n",
       "\n",
       "  QUEUE_SEC  BATCH_DATE  \n",
       "0         2   2018/7/31  \n",
       "1         9   2018/7/31  \n",
       "2         2   2018/7/31  \n",
       "3        44   2018/7/31  \n",
       "4        25   2018/7/31  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import following code automatically by clicking right icon of \"find data\" in top toolbar\n",
    "#select \"df_smf.csv\"-Insert Pandas DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "import dsx_core_utils\n",
    "from dsx_core_utils import ProjectContext\n",
    "# Add asset from data set\n",
    "PC = ProjectContext.ProjectContext('Batch_Job_Analytics', '1_BatchJob_SMF30Extract', '', 'xx.xx.xx.xx')\n",
    "FILE_PATH = dsx_core_utils.get_local_dataset(PC, 'DF_smf.csv')\n",
    "DF_DATA_1 = pd.read_csv(FILE_PATH)\n",
    "DF_DATA_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>EXCP</th>\n",
       "      <th>HQ_SEC</th>\n",
       "      <th>IO_CONN_SEC</th>\n",
       "      <th>IO_UNIT</th>\n",
       "      <th>JQ_SEC</th>\n",
       "      <th>MSO_UNIT</th>\n",
       "      <th>PAGE_IN</th>\n",
       "      <th>PAGE_OUT</th>\n",
       "      <th>PAGE_SWAP</th>\n",
       "      <th>...</th>\n",
       "      <th>TCB_CPU_MS</th>\n",
       "      <th>TCB_CPU_SEC</th>\n",
       "      <th>TCB_UNIT</th>\n",
       "      <th>START_SEC</th>\n",
       "      <th>REQUEST_SEC</th>\n",
       "      <th>END_SEC</th>\n",
       "      <th>ELAPSED_SEC</th>\n",
       "      <th>CPU_SEC</th>\n",
       "      <th>CPU_MS</th>\n",
       "      <th>QUEUE_SEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>207.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>...</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>172.463768</td>\n",
       "      <td>11266.067633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.188406</td>\n",
       "      <td>5.225798e+04</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>2.319452e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6541.507246</td>\n",
       "      <td>6.072464</td>\n",
       "      <td>4.495678e+06</td>\n",
       "      <td>1.533084e+09</td>\n",
       "      <td>1.533083e+09</td>\n",
       "      <td>1.533084e+09</td>\n",
       "      <td>33.151063</td>\n",
       "      <td>6.125604</td>\n",
       "      <td>6655.188406</td>\n",
       "      <td>21.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.777957</td>\n",
       "      <td>33806.621647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.136876</td>\n",
       "      <td>1.519144e+05</td>\n",
       "      <td>0.379954</td>\n",
       "      <td>1.235451e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22186.384600</td>\n",
       "      <td>21.032328</td>\n",
       "      <td>1.523614e+07</td>\n",
       "      <td>5.220820e+03</td>\n",
       "      <td>5.228407e+03</td>\n",
       "      <td>5.235676e+03</td>\n",
       "      <td>95.410931</td>\n",
       "      <td>21.298016</td>\n",
       "      <td>22574.096919</td>\n",
       "      <td>57.441522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.170000e+02</td>\n",
       "      <td>1.533081e+09</td>\n",
       "      <td>1.533081e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.170000e+03</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.827000e+04</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.020000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.067750e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.198550e+05</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>1.533082e+09</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>266848.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1.015707e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.162908e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>214389.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.472287e+08</td>\n",
       "      <td>1.533099e+09</td>\n",
       "      <td>1.533099e+09</td>\n",
       "      <td>1.533099e+09</td>\n",
       "      <td>600.170000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>218757.000000</td>\n",
       "      <td>288.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CLASS           EXCP  HQ_SEC  IO_CONN_SEC       IO_UNIT  \\\n",
       "count  207.000000     207.000000   207.0   207.000000  2.070000e+02   \n",
       "mean   172.463768   11266.067633     0.0     6.188406  5.225798e+04   \n",
       "std     44.777957   33806.621647     0.0    30.136876  1.519144e+05   \n",
       "min    100.000000       1.000000     0.0     0.000000  0.000000e+00   \n",
       "25%    100.000000       1.000000     0.0     0.000000  0.000000e+00   \n",
       "50%    200.000000      77.000000     0.0     0.000000  3.350000e+02   \n",
       "75%    200.000000    1460.000000     0.0     0.000000  7.020000e+03   \n",
       "max    200.000000  266848.000000     0.0   335.000000  1.015707e+06   \n",
       "\n",
       "           JQ_SEC      MSO_UNIT  PAGE_IN  PAGE_OUT  PAGE_SWAP     ...      \\\n",
       "count  207.000000  2.070000e+02    207.0     207.0      207.0     ...       \n",
       "mean     0.173913  2.319452e+06      0.0       0.0        0.0     ...       \n",
       "std      0.379954  1.235451e+07      0.0       0.0        0.0     ...       \n",
       "min      0.000000  9.000000e+00      0.0       0.0        0.0     ...       \n",
       "25%      0.000000  1.400000e+01      0.0       0.0        0.0     ...       \n",
       "50%      0.000000  4.360000e+02      0.0       0.0        0.0     ...       \n",
       "75%      0.000000  1.067750e+04      0.0       0.0        0.0     ...       \n",
       "max      1.000000  1.162908e+08      0.0       0.0        0.0     ...       \n",
       "\n",
       "          TCB_CPU_MS  TCB_CPU_SEC      TCB_UNIT     START_SEC   REQUEST_SEC  \\\n",
       "count     207.000000   207.000000  2.070000e+02  2.070000e+02  2.070000e+02   \n",
       "mean     6541.507246     6.072464  4.495678e+06  1.533084e+09  1.533083e+09   \n",
       "std     22186.384600    21.032328  1.523614e+07  5.220820e+03  5.228407e+03   \n",
       "min         0.000000     0.000000  9.170000e+02  1.533081e+09  1.533081e+09   \n",
       "25%         0.000000     0.000000  1.170000e+03  1.533082e+09  1.533082e+09   \n",
       "50%        14.000000     0.000000  1.827000e+04  1.533082e+09  1.533082e+09   \n",
       "75%       312.500000     0.000000  2.198550e+05  1.533082e+09  1.533082e+09   \n",
       "max    214389.000000   202.000000  1.472287e+08  1.533099e+09  1.533099e+09   \n",
       "\n",
       "            END_SEC  ELAPSED_SEC     CPU_SEC         CPU_MS   QUEUE_SEC  \n",
       "count  2.070000e+02   207.000000  207.000000     207.000000  207.000000  \n",
       "mean   1.533084e+09    33.151063    6.125604    6655.188406   21.768116  \n",
       "std    5.235676e+03    95.410931   21.298016   22574.096919   57.441522  \n",
       "min    1.533082e+09     0.000000    0.000000       0.000000    0.000000  \n",
       "25%    1.533082e+09     0.030000    0.000000       0.000000    0.000000  \n",
       "50%    1.533082e+09     0.500000    0.000000      14.000000    1.000000  \n",
       "75%    1.533082e+09     5.940000    0.000000     312.500000    3.500000  \n",
       "max    1.533099e+09   600.170000  206.000000  218757.000000  288.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_DATA_1.describe()"
   ]
  }
 ],
 "metadata": {
  "component": "zed7hdh1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
